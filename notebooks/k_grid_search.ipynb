{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Grid Search for hyper-parameter tuning of xgboost__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the somewhat erratic and therefore erratic nature eof our dataset, most likely classical time series models such as (S)ARIMA or Holt-Winters won't suffice here. Although we have identified regular time features such as seasonality, with lagging we take our time features beyond that which is outside the scope of classical time series forecast.\n",
    "\n",
    "In the data science community, xgboost is a commonly accepted non-classical algorithm for time forecasts. Care must be taken with that model as the problem of unseen data exists, i.e. whatever target values the model has not seen in training, it cannot predict in a test set. In our case, we know that marginal CO2 emissions are within a set range for the training as well as the test set (notebook 6: Mean of CO2 emsissions of per time point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt\n",
    "import joblib\n",
    "import csv\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../big_data/df_clean_interconnectors.pkl'\n",
    "df = pd.read_pickle(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO2E_EMISSIONS_FACTOR</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>minute_sin</th>\n",
       "      <th>minute_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>lag1</th>\n",
       "      <th>...</th>\n",
       "      <th>lag7</th>\n",
       "      <th>lag8</th>\n",
       "      <th>lag9</th>\n",
       "      <th>lag10</th>\n",
       "      <th>lag11</th>\n",
       "      <th>lag12</th>\n",
       "      <th>horizon0</th>\n",
       "      <th>demand</th>\n",
       "      <th>demand_capacity</th>\n",
       "      <th>interconnector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-09-01 00:00:00</th>\n",
       "      <td>0.986067</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>1.032780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938327</td>\n",
       "      <td>0.912643</td>\n",
       "      <td>0.798310</td>\n",
       "      <td>0.980592</td>\n",
       "      <td>0.473708</td>\n",
       "      <td>0.971761</td>\n",
       "      <td>0.986067</td>\n",
       "      <td>1667.12</td>\n",
       "      <td>0.603199</td>\n",
       "      <td>302.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-01 00:05:00</th>\n",
       "      <td>0.976360</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.986067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908518</td>\n",
       "      <td>0.938327</td>\n",
       "      <td>0.912643</td>\n",
       "      <td>0.798310</td>\n",
       "      <td>0.980592</td>\n",
       "      <td>0.473708</td>\n",
       "      <td>0.976360</td>\n",
       "      <td>1657.52</td>\n",
       "      <td>0.599962</td>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-01 00:10:00</th>\n",
       "      <td>0.976889</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.976360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.971761</td>\n",
       "      <td>0.908518</td>\n",
       "      <td>0.938327</td>\n",
       "      <td>0.912643</td>\n",
       "      <td>0.798310</td>\n",
       "      <td>0.980592</td>\n",
       "      <td>0.976889</td>\n",
       "      <td>1650.15</td>\n",
       "      <td>0.596877</td>\n",
       "      <td>290.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-01 00:15:00</th>\n",
       "      <td>1.032780</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.832769e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>0.976889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980592</td>\n",
       "      <td>0.971761</td>\n",
       "      <td>0.908518</td>\n",
       "      <td>0.938327</td>\n",
       "      <td>0.912643</td>\n",
       "      <td>0.798310</td>\n",
       "      <td>1.032780</td>\n",
       "      <td>1630.66</td>\n",
       "      <td>0.589438</td>\n",
       "      <td>260.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-01 00:20:00</th>\n",
       "      <td>0.975655</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>1.032780</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903942</td>\n",
       "      <td>0.980592</td>\n",
       "      <td>0.971761</td>\n",
       "      <td>0.908518</td>\n",
       "      <td>0.938327</td>\n",
       "      <td>0.912643</td>\n",
       "      <td>0.975655</td>\n",
       "      <td>1628.96</td>\n",
       "      <td>0.587282</td>\n",
       "      <td>256.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     CO2E_EMISSIONS_FACTOR  weekday  year  minute_sin  \\\n",
       "2009-09-01 00:00:00               0.986067        0  2009    0.000000   \n",
       "2009-09-01 00:05:00               0.976360        0  2009    0.500000   \n",
       "2009-09-01 00:10:00               0.976889        0  2009    0.866025   \n",
       "2009-09-01 00:15:00               1.032780        0  2009    1.000000   \n",
       "2009-09-01 00:20:00               0.975655        0  2009    0.866025   \n",
       "\n",
       "                       minute_cos  hour_sin  hour_cos  month_sin  \\\n",
       "2009-09-01 00:00:00  1.000000e+00       0.0       1.0       -1.0   \n",
       "2009-09-01 00:05:00  8.660254e-01       0.0       1.0       -1.0   \n",
       "2009-09-01 00:10:00  5.000000e-01       0.0       1.0       -1.0   \n",
       "2009-09-01 00:15:00  2.832769e-16       0.0       1.0       -1.0   \n",
       "2009-09-01 00:20:00 -5.000000e-01       0.0       1.0       -1.0   \n",
       "\n",
       "                        month_cos      lag1  ...      lag7      lag8  \\\n",
       "2009-09-01 00:00:00 -1.836970e-16  1.032780  ...  0.938327  0.912643   \n",
       "2009-09-01 00:05:00 -1.836970e-16  0.986067  ...  0.908518  0.938327   \n",
       "2009-09-01 00:10:00 -1.836970e-16  0.976360  ...  0.971761  0.908518   \n",
       "2009-09-01 00:15:00 -1.836970e-16  0.976889  ...  0.980592  0.971761   \n",
       "2009-09-01 00:20:00 -1.836970e-16  1.032780  ...  0.903942  0.980592   \n",
       "\n",
       "                         lag9     lag10     lag11     lag12  horizon0  \\\n",
       "2009-09-01 00:00:00  0.798310  0.980592  0.473708  0.971761  0.986067   \n",
       "2009-09-01 00:05:00  0.912643  0.798310  0.980592  0.473708  0.976360   \n",
       "2009-09-01 00:10:00  0.938327  0.912643  0.798310  0.980592  0.976889   \n",
       "2009-09-01 00:15:00  0.908518  0.938327  0.912643  0.798310  1.032780   \n",
       "2009-09-01 00:20:00  0.971761  0.908518  0.938327  0.912643  0.975655   \n",
       "\n",
       "                      demand  demand_capacity  interconnector  \n",
       "2009-09-01 00:00:00  1667.12         0.603199          302.86  \n",
       "2009-09-01 00:05:00  1657.52         0.599962          300.00  \n",
       "2009-09-01 00:10:00  1650.15         0.596877          290.52  \n",
       "2009-09-01 00:15:00  1630.66         0.589438          260.75  \n",
       "2009-09-01 00:20:00  1628.96         0.587282          256.98  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Splitting test and validation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to our lagging features, we will have to make a few conmsiderations regrading the train / validation split here.\n",
    "Have a closer look onto the table below. If we want to split our dataset into a train / test split, we have to think through a few points. Hypothetically, imagine we make a clean cut at any Timestamp > 2009-07-01 05:00:00. Then, almost all values of lag1 in the train set are present in lag12 of the test set. The same goes for all remaining lag columns to a lesser extent.\n",
    "\n",
    "This is leakage of training data into the validation set. Such leakage leads to an artificially increased predicition performance not corresponding to the performance of a completely unseem dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/lag_examples3.jpg\"> <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid leakage we write our own train - validation function which accounts for leakage by leaving a gap of the size of the max number of lags in between the train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_ts(df, relative_train, maximal_lag, horizon):\n",
    "    '''\n",
    "    Time series (ts) split function creates a train/test set under consideration of potential overlap between the two due to lag processing\n",
    "    X_train, y_train, X_test, y_test = ...\n",
    "    df=must contain target column as \"target\"; all other columns must be used as features\n",
    "    percentage_train=how much of the total dataset shall be used for training; must be added between 0 - 1\n",
    "    maximal_lag=out of all lag feature engineering, enter the maximal lag number\n",
    "    '''\n",
    "    k = int(df.shape[0] * relative_train)\n",
    "    data_train = df.iloc[:k,:]\n",
    "    #to avoid overlapping of train and test data, a gap of the maximal lag - 1 must be included between the two sets\n",
    "    data_test = df.iloc[k+maximal_lag:,:]\n",
    "    \n",
    "    assert data_train.index.max() < data_test.index.min()\n",
    "    \n",
    "    #returns in the sequence X_train, y_train, X_test, y_test\n",
    "    return (data_train.drop(columns=[f\"horizon{horizon}\",\"CO2E_EMISSIONS_FACTOR\"], axis=1), data_train[f\"horizon{horizon}\"],\n",
    "            data_test.drop(columns=[f\"horizon{horizon}\",\"CO2E_EMISSIONS_FACTOR\"], axis=1), data_test[f\"horizon{horizon}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = train_validation_ts(df, 0.8, 12, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['weekday', 'year', 'minute_sin', 'minute_cos', 'hour_sin', 'hour_cos',\n",
      "       'month_sin', 'month_cos', 'lag1', 'lag2', 'lag3', 'lag4', 'lag5',\n",
      "       'lag6', 'lag7', 'lag8', 'lag9', 'lag10', 'lag11', 'lag12', 'demand',\n",
      "       'demand_capacity', 'interconnector'],\n",
      "      dtype='object')\n",
      "Index(['weekday', 'year', 'minute_sin', 'minute_cos', 'hour_sin', 'hour_cos',\n",
      "       'month_sin', 'month_cos', 'lag1', 'lag2', 'lag3', 'lag4', 'lag5',\n",
      "       'lag6', 'lag7', 'lag8', 'lag9', 'lag10', 'lag11', 'lag12', 'demand',\n",
      "       'demand_capacity', 'interconnector'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n",
    "print(X_val.columns)\n",
    "\n",
    "print(type(y_train))\n",
    "print(type(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __train xgboost__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "below you find a set of hyperparameters which were tested for optimal forecasting results of our dataset.\n",
    "The most relevant ones appeared to be learning rate, max_depth, n_estimators, and eta (not all reflected in this notebook). For the train / validation, the parameters with the best outcome were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.01, 0.1],\n",
       " 'max_depth': [50],\n",
       " 'n_estimators': [100],\n",
       " 'reg_alpha': [0.05],\n",
       " 'reg_lambda': [0]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = [0.01, 0.1] #learning_rate\n",
    "max_depth = [50]\n",
    "n_estimators = [100]\n",
    "reg_alpha = [0.05]\n",
    "reg_lambda = [0]\n",
    "\n",
    "params = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"max_depth\": max_depth,\n",
    "    \"n_estimators\": n_estimators,\n",
    "    \"reg_alpha\": reg_alpha,\n",
    "    \"reg_lambda\": reg_lambda,\n",
    "}\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Most importantly: time series split__\n",
    "\n",
    "Therefore, we use the time series split function built into sklearn (tscv = TimeSeriesSplit(n_splits=n_splits)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __K-fold cross validation__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/Kfold_CV.png\"> <br/>\n",
    "source: scikit-learn.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Time series split__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/time_series_split.png\"> <br/>\n",
    "source: datascience.stackexchange.com\n",
    "<br/>\n",
    "<br/>\n",
    "__Note: the sklearn tscv does not account for leakiness__\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGB_GS_ts(X_train, y_train, params,run, n_splits=2, n_jobs=7, verbose=5):\n",
    "    '''\n",
    "    Function performs GridSearch using TimeSeries CV\n",
    "    X_train, y_train\n",
    "    n_splits=number of splits in TimeSeriesCV; default:3\n",
    "    n_jobs=default: -1\n",
    "    verbose=default:5\n",
    "    '''\n",
    "    \n",
    "    model = xgb.XGBRegressor()\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    gsearch = GridSearchCV(estimator=model, cv=tscv,\n",
    "                            param_grid=params, n_jobs=n_jobs, verbose=verbose)\n",
    "\n",
    "    gsearch.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best params were: {}\".format(gsearch.best_params_))\n",
    "    \n",
    "    pd.DataFrame(gsearch.cv_results_).to_csv('{}/nem-data/trainings/grid_searches/{}_GS.csv'.format(os.environ['HOME'],run))\n",
    "    joblib.dump(gsearch, '{}/nem-data/trainings/gridsearches/{}_GS_object.pkl'.format(os.environ['HOME'], run))\n",
    "    \n",
    "    best_model = gsearch.best_estimator_\n",
    "    \n",
    "    error_test = np.sqrt(mse(y_test, best_model.predict(X_test))/y_test.mean())\n",
    "    error_train = np.sqrt(mse(y_train, best_model.predict(X_train))/y_train.mean())\n",
    "    compare_train_test_error = abs(error_test - error_train)\n",
    "    \n",
    "    settings = {\n",
    "    \"Model\": \"XGBoost\",\n",
    "    \"Feature Description\": \"sine_cosine, lag_12, horizon=0, demand, capacity, interconnectors\",\n",
    "    \"Model Description\": gsearch.best_params_\n",
    "    }\n",
    "\n",
    "    print(f\"Root mean squared percentage error: {error_train, error_test}\")\n",
    "    log_test_results(\n",
    "        settings, error_train, error_test,\n",
    "        compare_train_test_error, run\n",
    "    )\n",
    "    \n",
    "    return gsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=7)]: Using backend LokyBackend with 7 concurrent workers.\n",
      "[Parallel(n_jobs=7)]: Done   2 out of   4 | elapsed:  9.6min remaining:  9.6min\n",
      "[Parallel(n_jobs=7)]: Done   4 out of   4 | elapsed: 19.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=7)]: Done   4 out of   4 | elapsed: 19.0min finished\n",
      "/home/bastian/Environment/DSR_portfolio/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/home/bastian/Environment/DSR_portfolio/lib/python3.6/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:29:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Best params were: {'learning_rate': 0.1, 'max_depth': 50, 'n_estimators': 100, 'reg_alpha': 0.05, 'reg_lambda': 0}\n",
      "Root mean squared percentage error: (0.004771012911918365, 0.35569846008739964)\n"
     ]
    }
   ],
   "source": [
    "gsearch = XGB_GS_ts(X_train,y_train,params,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_test_results(settings, error_train, error_test, train_test_error_difference, file_name):\n",
    "    csv_path = '{}/nem-data/trainings/grid_searches/{}_GS_log.csv'.format(os.environ['HOME'], file_name)\n",
    "    must_add_headers = False if os.path.isfile(csv_path) else True\n",
    "\n",
    "    with open(csv_path, mode='a') as test_results:\n",
    "        writer = csv.writer(test_results,\n",
    "                            delimiter=',',\n",
    "                            quotechar='\"',\n",
    "                            quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        if must_add_headers:\n",
    "            writer.writerow([\n",
    "                'Model', 'Feature Description', \"Model Description\", \"Training error\", \"Test error\",\n",
    "                \"Difference_train_test_error\"\n",
    "            ])\n",
    "        writer.writerow([\n",
    "            settings[\"Model\"], settings[\"Feature Description\"],\n",
    "            str(settings[\"Model Description\"]), error_train, error_test,\n",
    "            train_test_error_difference\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Best params__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the outcomes in the folder 'grid_searches'.\n",
    "\n",
    "Note that your results might slightly vary since you may be using more NEMDE data as they are being updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 5\n",
    "learning_rate = 0.1\n",
    "num_estimators = 100\n",
    "reg_alpha = 0.05\n",
    "reg_lambda = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr_teaching",
   "language": "python",
   "name": "dsr_teaching"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
