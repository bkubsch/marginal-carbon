{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final code\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_xml_to_dataframe(path_chunks, path_destination):\n",
    "    '''\n",
    "    Divide whole dataset into chunks procssable for available computing power.\n",
    "    E.g. divide 10,000 files into 10 x 1000 files chunks. Per chunk, prepare one folder for 1000 files each time (here: 10 folders)\n",
    "    path_chunks=\"directory to location of chunks to parsed\"\n",
    "    path destination=\"directory to store chunks as one file at a time (here: 10 files)\"\n",
    "    '''\n",
    "    len(os.listdir(path_chunks))\n",
    "    lst = list(range(1,len(os.listdir(path_chunks)) + 1))\n",
    "\n",
    "    for i in lst:\n",
    "        print(i)\n",
    "        path_chunk_i = path_chunks + '/{}'.format(i)\n",
    "        print(path_chunk_i)\n",
    "        glob.glob(path_chunk_i)\n",
    "        os.chdir(path_chunk_i)\n",
    "\n",
    "        extension = 'xml'\n",
    "        all_filenames = [i for i in glob.glob('**/*.{}'.format(extension), recursive=True)]\n",
    "\n",
    "        print(len(all_filenames))\n",
    "\n",
    "        data = []\n",
    "        for j in all_filenames:\n",
    "            root = ET.parse(j).getroot()\n",
    "            attributes = ([c.attrib for c in root])\n",
    "            for k in attributes:\n",
    "                data.append(k)\n",
    "\n",
    "        print(\"Next please\")\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_pickle(path_destination + '/{}.pkl'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "/home/bastian/nem-data/nemde_chunk/1\n",
      "87552\n",
      "Next please\n",
      "2\n",
      "/home/bastian/nem-data/nemde_chunk/2\n",
      "87551\n",
      "Next please\n",
      "3\n",
      "/home/bastian/nem-data/nemde_chunk/3\n",
      "88128\n",
      "Next please\n",
      "4\n",
      "/home/bastian/nem-data/nemde_chunk/4\n",
      "87840\n",
      "Next please\n",
      "5\n",
      "/home/bastian/nem-data/nemde_chunk/5\n",
      "87548\n",
      "Next please\n",
      "6\n",
      "/home/bastian/nem-data/nemde_chunk/6\n",
      "87264\n",
      "Next please\n",
      "7\n",
      "/home/bastian/nem-data/nemde_chunk/7\n",
      "87553\n",
      "Next please\n",
      "8\n",
      "/home/bastian/nem-data/nemde_chunk/8\n",
      "87841\n",
      "Next please\n",
      "9\n",
      "/home/bastian/nem-data/nemde_chunk/9\n",
      "88130\n",
      "Next please\n",
      "10\n",
      "/home/bastian/nem-data/nemde_chunk/10\n",
      "87552\n",
      "Next please\n",
      "11\n",
      "/home/bastian/nem-data/nemde_chunk/11\n",
      "69982\n",
      "Next please\n",
      "12\n",
      "/home/bastian/nem-data/nemde_chunk/12\n",
      "96527\n",
      "Next please\n"
     ]
    }
   ],
   "source": [
    "path_chunks = \"{}/nem-data/nemde_chunk\".format(os.environ['HOME'])\n",
    "path_destination = \"{}/nem-data/nemde_clean/chunks_clean\".format(os.environ['HOME'])\n",
    "\n",
    "parse_xml_to_dataframe(path_chunks, path_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
